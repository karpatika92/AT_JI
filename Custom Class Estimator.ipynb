{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start from the simplest part, the gini_impurity\n",
    "def _gini_impurity(y_pred,y_true, threshold):\n",
    "    \"\"\"Computes the gini impurity of a split.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray, shape (n_samples,)\n",
    "        Array of true classes, must be either 0 or 1.\n",
    "    y_pred : ndarray, shape (n_samples,)\n",
    "        Array of predicted probabilities, must be between 0 and 1.\n",
    "    threshold : float\n",
    "        The value for cutting y.\n",
    "    Returns\n",
    "    -------\n",
    "    out : float\n",
    "        gini impurity\n",
    "        \n",
    "    References\n",
    "    ----------\n",
    "    Wikipedia - Decision Tree Learning\n",
    "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    \n",
    "    A Simple Explanation of Gini Impurity\n",
    "    https://victorzhou.com/blog/gini-impurity/\n",
    "    \"\"\"\n",
    "    #check if y is indeed a probability vector\n",
    "    if not (np.max(y_pred)<=1)&(np.min(y_pred)>=0):\n",
    "        raise ValueError(\"y_pred must be probabilities\")\n",
    "    \n",
    "    if len(np.unique(y_true))!=2:\n",
    "        raise ValueError(\"y_true must be binary labels\")\n",
    "    \n",
    "    #now split the y vector and calculate the gini impurity by the wikipedia formula\n",
    "    #source: https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "    #source 2:https://victorzhou.com/blog/gini-impurity/\n",
    "    y_label_predicted=np.where(y_pred>threshold,1,0)\n",
    "    #then get the predicted classes and the true classes\n",
    "    class_dict={}\n",
    "    #check if both labels exist\n",
    "    if len(np.unique(y_label_predicted))==2:\n",
    "        for label in [0,1]:\n",
    "            #print(label)\n",
    "            class_dict[label]={}\n",
    "            class_dict[label][\"prob_1\"]=np.mean(y_true[y_label_predicted==label])\n",
    "            class_dict[label][\"weigth\"]=np.sum(y_label_predicted==label)/len(y_label_predicted)\n",
    "            class_dict[label][\"gini\"]=1-(class_dict[label][\"prob_1\"]*class_dict[label][\"prob_1\"]+\\\n",
    "                                         (1-class_dict[label][\"prob_1\"])*(1-class_dict[label][\"prob_1\"]))\n",
    "        #print(class_dict)\n",
    "        out=class_dict[0][\"weigth\"]*class_dict[0][\"gini\"]+class_dict[1][\"weigth\"]*class_dict[1][\"gini\"]\n",
    "    else:\n",
    "        #if there is only one label after the split, the gini must be calculated for the whole dataset\n",
    "        prob_1=np.mean(y_true)\n",
    "        out=1-(prob_1*prob_1+(1-prob_1)*(1-prob_1))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, we create the thresholdbinarizer\n",
    "#this class will take as an input y_true and y_pred, and will cycle through all possible threshold values to find the best split\n",
    "class ThresholdBinarizer(BaseEstimator,TransformerMixin):\n",
    "    \"\"\"\n",
    "    ThresholdBinarizer custom transformer\n",
    "    \n",
    "    The class implements a solution to find the optimal splitting threshold  in a vector\n",
    "    of predicted probabilities, while knowing the true labels. The metric used for splitting is \n",
    "    the gini impurity\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    There are no parameters, only the predicted probabilities and the true classes are required\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    optimal_threshold : The calculated optimal threshold, that minimizes the gini impurity\n",
    "    \n",
    "    optimal_gini : The lowest achievable gini impurity\n",
    "    \n",
    "    Example\n",
    "    --------\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    X,y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "    clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "    y_pred = clf.predict_proba(X)[:,0]\n",
    "\n",
    "    binarizer=ThresholdBinarizer()\n",
    "    binarizer.fit(y_pred,y)\n",
    "    y_labels=binarizer.transform(y_pred)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Called when initializing the binarizer\n",
    "        \"\"\"\n",
    "        \n",
    "    def fit(self, y_pred,y_true,step=1000):\n",
    "        \"\"\"\n",
    "        This should fit transformer. The purpose here is to find the optimal threshold to  cut the predicted probabilities.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        y_pred : predicted probabilities for the classes\n",
    "        \n",
    "        y_true : the true labels of the instances\n",
    "        \n",
    "        step : the optimizer checks every k/step rationals for the gini split for k=0 to step.\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        self : object\n",
    "        \n",
    "        Notes\n",
    "        -----------\n",
    "        This step optimizes the treshold by trying every values with a 1/step on the [0,1] interval. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.optimal_threshold=0\n",
    "        self.optimal_gini=_gini_impurity(y_pred,y_true, 0)\n",
    "        print(\"STARTING GINI {}\".format(self.optimal_gini))\n",
    "        \n",
    "        for threshold_ in np.arange(step)/step:\n",
    "            _gini=_gini_impurity(y_pred,y_true, threshold_)\n",
    "            #test if split is better than current best\n",
    "            if _gini<self.optimal_gini:\n",
    "                self.optimal_gini=_gini\n",
    "                self.optimal_threshold=threshold_\n",
    "        print(\"OPTIMAL THRESHOLD: {}\".format(self.optimal_threshold))\n",
    "        print(\"BEST GINI: {}\".format(self.optimal_gini))\n",
    "\n",
    "        return self\n",
    "   \n",
    "    def transform(self,y_pred):\n",
    "        \"\"\"This fitted classifier cuts the input vector accordng to the previously\n",
    "        calculated optimal threshold\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        y_pred : the predicted probabilities\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        out : array (n_samples,)\n",
    "            an array of class labels\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #check if the transformer was fitteed\n",
    "        try:\n",
    "            getattr(self, \"optimal_threshold\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must fit the transformer before transforming data!\")\n",
    "        #cut according to threshold\n",
    "        out = np.where(y_pred>self.optimal_threshold,1,0)\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_estimator(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"A classifier I built for Aliz Tech job interview\n",
    "    The purpose of this estimator is to fit a logistic regression on a binary classification task,\n",
    "    then predict probabilities, and use a ThresholdBinarizer to assign labels according to the\n",
    "    optimal minimum Gini impurity\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : an instance of a LogisticRegression from sklearn, custom properties can be defined\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    fitted_ : True, if the fit method has been executed\n",
    "    \n",
    "    estimator : the estimator passed to the _init_ method, defaults to LogisticRegression()\n",
    "    \n",
    "    y_pred : predicted probabilities by the estimator\n",
    "    \n",
    "    _binarizer : the ThresholdBinarizer instance to assign class labels\n",
    "    \n",
    "\n",
    "    Example\n",
    "    --------\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "    X,y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "\n",
    "    myEstimator=custom_estimator()\n",
    "    myEstimator.fit(X,y)\n",
    "    myEstimator.predict(X)    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, estimator=LogisticRegression()):\n",
    "        \"\"\"\n",
    "        Called when initializing the classifier\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        \n",
    "        estimator : the LogisticRegression instance used for restimating the outcome probabilities\n",
    "        \n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "\n",
    "\n",
    "    def fit(self, X, y_true):\n",
    "        \"\"\"\n",
    "        This method fits the classifier to the inputdata features (X) and the true labels (y_true).\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X : array (n_samples,n_features), array of features used for predicting the outcome\n",
    "        \n",
    "        y_true : array (n_samples,); array of labels for training examples\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        assert isinstance(self.estimator,LogisticRegression),\"Estimator must be an instance of LogisticRegression\"\n",
    "\n",
    "        assert (len(np.unique(y_true))==2), \"Labels must be binary\"\n",
    "        self.y_true=y_true\n",
    "        self.estimator.fit(X,self.y_true)\n",
    "        self.fitted_=True\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        This method predicts probabilities\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X : array (n_samples,n_features), array of features used for predicting the outcome\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        y_pred : array (n_samples,); vector of predicted probabilities\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            getattr(self, \"fitted_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        \n",
    "        self.y_pred=self.estimator.predict_proba(X)[:,0]\n",
    "        \n",
    "        #now binarize the prediction\n",
    "        return self.y_pred\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        This method assigns class labels using ThresholdBinarizer to minimize gini impurity\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X : array (n_samples,n_features), array of features used for predicting the outcome\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        self.y_labels : array (n_samples,); vector of predicted labels\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            getattr(self, \"fitted_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "        \n",
    "        try:\n",
    "            getattr(self, \"y_pred\")\n",
    "        except AttributeError:\n",
    "            self.y_pred=self.estimator.predict_proba(X)[:,0]\n",
    "        \n",
    "        self._binarizer=ThresholdBinarizer()\n",
    "        self._binarizer.fit(self.y_pred,self.y_true)\n",
    "        self.y_labels=self._binarizer.transform(self.y_pred)\n",
    "        return self.y_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
